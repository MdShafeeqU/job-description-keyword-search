{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keybert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import openai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# from keybert.llm import OpenAI\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeybert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyLLM\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeybert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyBERT\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keybert'"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "# from keybert.llm import OpenAI\n",
    "from keybert import KeyLLM\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data.txt\", 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "I have the following Job Description\n",
    "{data}\n",
    "\n",
    "\n",
    "Based on the above job description, extract keywords the best describe the skillsets, technologies, languages, education and experience of the job role.\n",
    "Make sure to extract keywords that appear in text\n",
    "Use the following format separated by commas: \n",
    "<keywords>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "# key_model_multi = Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('developer', 0.3985), ('engineers', 0.3769), ('pipeline', 0.3664), ('engineer', 0.3663), ('pipelines', 0.3469), ('reporting', 0.3402), ('jobs', 0.3364), ('resume', 0.3192), ('san', 0.3073), ('roles', 0.3022)]\n"
     ]
    }
   ],
   "source": [
    "keywords = kw_model.extract_keywords(data, top_n=10)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create your LLM\n",
    "# openai.api_key = \"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\"\n",
    "# llm = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "I have the following Job Description\n",
    "{data}\n",
    "\n",
    "\n",
    "Based on the above job description, extract keywords the best describe the skillsets, technologies, languages, education and experience of the job role.\n",
    "Make sure to extract keywords that appear in text\n",
    "Use the following format separated by commas: \n",
    "<keywords>\n",
    "\"\"\"\n",
    "\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m key_model \u001b[38;5;241m=\u001b[39m KeyLLM(llm)\n\u001b[1;32m----> 3\u001b[0m keywords \u001b[38;5;241m=\u001b[39m \u001b[43mkey_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_keywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(keywords)\n",
      "File \u001b[1;32mc:\\Projects\\job-description-keyword-search\\env\\lib\\site-packages\\keybert\\_llm.py:126\u001b[0m, in \u001b[0;36mKeyLLM.extract_keywords\u001b[1;34m(self, docs, check_vocab, candidate_keywords, threshold, embeddings)\u001b[0m\n\u001b[0;32m    123\u001b[0m         keywords \u001b[38;5;241m=\u001b[39m [in_cluster_keywords[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(docs))]\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# Extract keywords using a Large Language Model (LLM)\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_keywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_keywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Only extract keywords that appear in the input document\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_vocab:\n",
      "File \u001b[1;32mc:\\Projects\\job-description-keyword-search\\env\\lib\\site-packages\\keybert\\llm\\_openai.py:185\u001b[0m, in \u001b[0;36mOpenAI.extract_keywords\u001b[1;34m(self, documents, candidate_keywords)\u001b[0m\n\u001b[0;32m    183\u001b[0m         response \u001b[38;5;241m=\u001b[39m completions_with_backoff(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, prompt\u001b[38;5;241m=\u001b[39mprompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator_kwargs)\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, prompt\u001b[38;5;241m=\u001b[39mprompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator_kwargs)\n\u001b[0;32m    186\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    187\u001b[0m keywords \u001b[38;5;241m=\u001b[39m [keyword\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m keywords\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Projects\\job-description-keyword-search\\env\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "key_model = KeyLLM(llm)\n",
    "\n",
    "keywords = key_model.extract_keywords(data, check_vocab=True)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using gemini pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"Develop data pipelines to extract, transform, and load (ETL) data from multiple sources into a centralized data repository\n",
    "Improve and refine data pipelines for efficiency, reliability, and scalability\n",
    "Monitor and troubleshoot data pipeline issues and ensure data integrity\n",
    "We use Python, Airflow, Snowflake, Hive, MySQL, Kinesis, Kafka and AWS (Amazon Web Services)\n",
    "API Development: Develop RESTful APIs & microservices to support multiple operations\n",
    "Follow best practices for security, scaling, cost effectiveness and testing\n",
    "Create unit and integration tests\n",
    "Contribute to documentation on use of the APIs\n",
    "Problem Solving: Resolve technical issues and bugs in applications\n",
    "Identify performance bottlenecks and improve code and databases\n",
    "Team Collaboration: Collaborate with engineers, analysts, corss-functional teams and partners to understand data requirements and deliver relevant insights\n",
    "Performance Optimization: Improve data processing and query performance for data retrieval and analytics\n",
    "Code Review and Documentation: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=\"insert your api key\")\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> JavaScript, ReactJS, NodeJS, MySQL, PostgreSQL, MongoDB, AWS, GCP, Linux, Docker, Kubernetes, Git, Jira, Confluence"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.generate_content(\"\"\"\n",
    "I have the following Job Description:\n",
    "\n",
    "{document}\n",
    "\n",
    "Based on the above job description, extract technical keywords that best describe the skillsets and technologies required for the above job. Pay special attention to programming languages, tools, and technologies mentioned.\n",
    "\n",
    "Use the following format separated by commas:\n",
    "<keywords>\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
